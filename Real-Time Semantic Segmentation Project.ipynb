{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for net_encoder\n",
      "Loading weights for net_decoder\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import torchvision.transforms as transforms\n",
    "from mit_semseg.models import ModelBuilder, SegmentationModule\n",
    "from mit_semseg.utils import colorEncode\n",
    "import scipy.io\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Clear any cached data in GPU\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Import model components from the semantic segmentation library\n",
    "from mit_semseg.models import ModelBuilder, SegmentationModule\n",
    "from mit_semseg.utils import colorEncode\n",
    "# Load the semantic segmentation model components\n",
    "net_encoder = ModelBuilder.build_encoder(\n",
    "    arch='resnet50dilated',\n",
    "    fc_dim=2048,\n",
    "    weights='encoder_epoch.pth')\n",
    "net_decoder = ModelBuilder.build_decoder(\n",
    "    arch='ppm_deepsup',\n",
    "    fc_dim=2048,\n",
    "    num_class=150,\n",
    "    weights='decoder_epoch.pth',\n",
    "    use_softmax=True)\n",
    "\n",
    "crit = torch.nn.NLLLoss(ignore_index=-1)\n",
    "segmentation_module = SegmentationModule(net_encoder, net_decoder, crit)\n",
    "segmentation_module.eval()\n",
    "segmentation_module.cuda()\n",
    "\n",
    "# Load colors and names for visualization\n",
    "colors = scipy.io.loadmat('data/color150.mat')['colors']\n",
    "\n",
    "# Function to visualize segmentation results\n",
    "def visualize_result(img, pred):\n",
    "    pred_color = colorEncode(pred, colors).astype(np.uint8)\n",
    "    im_vis = np.concatenate((img, pred_color), axis=1)\n",
    "    return PIL.Image.fromarray(im_vis)\n",
    "\n",
    "# Transform for input images\n",
    "pil_to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create an output directory if it doesn't exist\n",
    "output_dir = \"output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "# Load colors and names for visualization\n",
    "colors = scipy.io.loadmat('data/color150.mat')['colors']\n",
    "\n",
    "# Load class names\n",
    "names = {}\n",
    "with open('data/object150_info.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        names[int(row[0]) - 1] = row[5].split(\";\")[0]  # Adjust the index\n",
    "\n",
    "# Function to visualize specific segmentation results\n",
    "def visualize_class(img, pred, class_index, class_name):\n",
    "    pred_class = pred.copy()\n",
    "    pred_class[pred_class != class_index] = -1\n",
    "    pred_color = colorEncode(pred_class, colors).astype(np.uint8)\n",
    "    im_vis = np.concatenate((img, pred_color), axis=1)\n",
    "    im_vis_pil = PIL.Image.fromarray(im_vis)\n",
    "    draw = PIL.ImageDraw.Draw(im_vis_pil)\n",
    "    draw.text((20, 20), class_name, fill=(255, 255, 255))\n",
    "    return im_vis_pil\n",
    "\n",
    "\n",
    "# Initialize the camera\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Variables to store the modes and class index\n",
    "realtime_mode = True\n",
    "type_visualization = False\n",
    "current_class_index = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Convert frame to PIL Image\n",
    "    cv2_im = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_im = PIL.Image.fromarray(cv2_im)\n",
    "\n",
    "    # Preprocess image\n",
    "    img_data = pil_to_tensor(pil_im)\n",
    "    singleton_batch = {'img_data': img_data[None].cuda()}\n",
    "    output_size = img_data.shape[1:]\n",
    "\n",
    "    # Handling key inputs\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:  # Esc key\n",
    "        break\n",
    "    elif k == ord(' '):  # Space key\n",
    "        realtime_mode = not realtime_mode\n",
    "    elif k == 9:  # Shift key\n",
    "        type_visualization = not type_visualization\n",
    "    elif k >= ord('1') and k <= ord('9'):\n",
    "        current_class_index = k - ord('1')\n",
    "    elif k >= ord('a') and k <= ord('f'):\n",
    "        current_class_index = k - ord('a') + 9\n",
    "\n",
    "    if realtime_mode or k == 13:  # Enter key for non-realtime mode\n",
    "        # Perform segmentation\n",
    "        with torch.no_grad():\n",
    "            scores = segmentation_module(singleton_batch, segSize=output_size)\n",
    "        _, pred = torch.max(scores, dim=1)\n",
    "        pred = pred.cpu()[0].numpy()\n",
    "\n",
    "        # Determine the most common classes\n",
    "        predicted_classes = np.bincount(pred.flatten()).argsort()[::-1]\n",
    "\n",
    "        # Visualize result\n",
    "        if type_visualization and current_class_index < len(predicted_classes):\n",
    "            class_index = predicted_classes[current_class_index]\n",
    "            class_name = names.get(class_index, \"Unknown\")\n",
    "            vis_im = visualize_class(cv2_im, pred, class_index, class_name)\n",
    "            vis_im = np.array(vis_im)\n",
    "            cv2.imshow(\"Semantic Segmentation\", cv2.cvtColor(vis_im, cv2.COLOR_RGB2BGR))\n",
    "        else:\n",
    "            vis_im = visualize_result(cv2_im, pred)\n",
    "            vis_im = np.array(vis_im)\n",
    "            cv2.imshow(\"Semantic Segmentation\", cv2.cvtColor(vis_im, cv2.COLOR_RGB2BGR))\n",
    "    else:\n",
    "        # Display the live camera feed in non-realtime mode\n",
    "        cv2.imshow(\"Camera Feed\", frame)\n",
    "\n",
    "    # Save the current frame and segmentation with 's' key\n",
    "    if k == ord('s'):\n",
    "        cv2.imwrite(\"captured_frame.jpg\", frame)\n",
    "        if 'vis_im' in locals():\n",
    "            PIL.Image.fromarray(vis_im).save(\"segmented_frame.jpg\")\n",
    "        print(\"Frame and segmentation result saved.\")\n",
    "\n",
    "# Release the camera and destroy all windows\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
